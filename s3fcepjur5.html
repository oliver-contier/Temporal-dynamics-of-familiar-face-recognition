<div></div><h2 data-label="718029" class="ltx_title_subsection">Habituation of familiar faces</h2><div>Similarly, the neural response to familiar faces might habituate over time in some of these areas; this possible neural adaptation has been largely ignored in previous studies. In this project, we want to investigate the temporal dynamics of core and extend system areas by extending the analysis on a previously acquired fMRI dataset where subjects were presented with personally familiar and unfamiliar faces. Our project will aim at further disentangling the roles of the areas associated with familiar face processing.</div><h2 data-label="156016" class="ltx_title_subsection">Hypotheses</h2><ol><li>As unfamiliar faces are repeatedly presented over the course of an experiment, we expect them to become increasingly visually familiar. We therefore predict that the contrast of &nbsp;Familiar vs. nfamiliar faces will decrease over time in the FFA (fusiform face area ; Kanwisher et al., 1997).</li><li>Visually induced familiarity has also been shown to evoke increased activity in the precuneus (Gobbini &amp; Haxby, 2006). We aim to replicate this effect and hence predict a decrease of the contrast between the response of to familiar and unfamiliar faces in the precuneus.</li><li>In previous analysis of this dataset, we have not observed any effect of familiarity in the amygdala—an area that is usually associated with the evaluation of familiar faces (Gobbini et al., 2004; Leibenluft et al., 2004). We predict that by better modeling the habituation effects, we &nbsp;will be able to detect an effect of familiarity in the amygdala, with greater response to unfamiliar than familiar faces.</li></ol><h2 data-label="160915" class="ltx_title_subsection">benefits of reanalysis</h2><div>To address these hypotheses we reanalysed an existing fMRI dataset from an experiment where subjects were presented with personally familiar and unfamiliar faces. The dataset is described fully in&nbsp;<cite class="ltx_cite raw v1">\citet*{Visconti_di_Oleggio_Castello_2017}</cite>.&nbsp;By addressing new hypotheses while reusing previously collected and analyzed data, we hoped to not only obtain a better value of the acquired and shared dataset, but also possibly to avoid new bugs and errors which could be present if new data was collected.</div><h1 data-label="980974" class="ltx_title_section">Methods</h1><div>We reanalysed an existing fMRI dataset from an experiment where 33 participants (mean age 23 y.o. +/- 3.33 SD, 13 males)<b>&nbsp;</b>were presented with pictures of personally familiar and unfamiliar faces while engaged in an oddball task. &nbsp;For a complete description of the participants, stimuli, procedure, image acquisition and preprocessing steps see&nbsp;<cite class="ltx_cite raw v1">\citet{Visconti_di_Oleggio_Castello_2017}</cite>. Of particular importance for this reanalysis was that the scanning sessions comprised of eleven functional runs which allowed us to model habituation effects over the course of the experiment in form of an extended second level model&nbsp;(see GLM analysis).</div><h2 data-label="300283" class="ltx_title_subsection">Preregistration</h2><div>In order to draw a clear distinction between confirmatory and exploratory results, the code for the data simulation and the confirmatory GLM analysis was preregistered on the Open Science Framework (<a href="https://osf.io/xj5cz/">https://osf.io/xj5cz/</a>).&nbsp;Additional exploratory analyses included adding simple main effects (One-Sample T-Test) for familiar and unfamiliar faces to the  first level analysis of the GLM as well as an exploratory ROI analysis.</div><h2 data-label="416316" class="ltx_title_subsection">GLM analysis</h2><div>Our confirmatory analysis comprised of a  hierarchical general linear model (GLM).The GLM analysis was performed using FSL (version 5.0.9;&nbsp;<cite class="ltx_cite raw v1">\citealp{Jenkinson_2012}</cite>) and implemented in Nipype (version 0.11.0;&nbsp;<cite class="ltx_cite raw v1">\citealt{Gorgolewski_2011}</cite>). The first and third level analysis were performed analogous to the GLM analysis in&nbsp;<cite class="ltx_cite raw v1">\citet{Visconti_di_Oleggio_Castello_2017}</cite>. The second-level analysis (fixed-effects) was extended to model  differences between the functional runs within each subject. To this end, the run number was introduced to the second level model as a regressor in addition to a simple averaging regressor. This effectively resulted in a model with an intercept and a slope, where the intercept is intended to capture the average effect of familiarity and the slope a linear change over the course of the experiment. A One-Sample T-Test was performed on the intercept and slope for each contrast from the first level analysis and the resulting statistical maps were passed on to the third level analysis (random effects). The resulting statistical maps were corrected for multiple comparisons with a voxel z-threshold set at 2.3, and cluster p-value of p = .05,&nbsp;using FSL’s cluster routine.</div><h2 data-label="187373" class="ltx_title_subsection">Simulation</h2><div>In order to validate the GLM  pipeline without gaining insights into potential results, we ran it on simulated data which used the original data as a pedestal. The simulated data was designed to contain topologically distinct signals for both an average and habitual effect of familiarity. This way, it provided an opportunity to test the ability of our expanded second level  model to differentiate between these two kinds of signals. The code used for this data simulation can be found in the scripts&nbsp;<i>famface_simulation_functions.py</i>&nbsp;and&nbsp;<i>famface_simulation_main.py</i> and uses functions from PyMVPA&nbsp;<cite class="ltx_cite raw v1">\citep*{Hanke_2009}</cite>. First,  an initial motion correction was performed on each original image using FSL's MCFLIRT&nbsp;<cite class="ltx_cite raw v1">\citep{Jenkinson_2001,Jenkinson_2002}</cite> as implemented in Nipype&nbsp;<cite class="ltx_cite raw v1">\citep{Gorgolewski_2011}</cite>. A mean image was then computed for each functional image by averaging each voxel over its time points. This mean image was re-expanded to its original number of time points by adding temporally autocorrelated noise to each voxel. The stimulus onsets for familiar and unfamiliar faces from the respective functional runs were convolved with a double-gamma function to model a BOLD response. To model an effect of familiarity, the amplitudes of these BOLD responses were chosen to be 8% signal change for familiar faces and 1% for unfamiliar faces respectively. This modelled signal was then added to two arbitrarily selected ROIs defined in MNI space (radius = 10 mm; [x, y, z] coordinates were [10, - 94, &nbsp;4] and [14, 44, 12]). The ROI mask was projected to individual subject space using FSL's FLIRT&nbsp;<cite class="ltx_cite raw v1">\citep{Jenkinson_2001,Jenkinson_2002}</cite>. For one of these ROIs, a habituation of the familiarity effect was mimicked by  increasing the amplitude of the modelled response to unfamiliar faces by 0.5 % signal change with each run number.</div><ul><li>Details about transformation method of ROI mask.</li></ul><div>The results of our GLM on the simulated data revealed that the modified second level model was able to differentiate between an average and a habitual effect of familiarity. While the intercept revealed significant clusters in both manipulated ROIs, only the ROI where a habitual effect was simulated was picked up by the slope (see Supplementary Material, Figure XXX).</div><ul><li>Second attempt</li></ul><h2 data-label="111638" class="ltx_title_subsection">ROI analysis</h2><div>In addition to our confirmatory GLM, an exploratory ROI analysis was performed.&nbsp;<cite class="ltx_cite raw v1">\citet{Visconti_di_Oleggio_Castello_2017}</cite> selected 30 non-overlapping spherical ROIs (10 mm radius) based on searchlight results from familiarity and identity classification. Additionally, we defined 8 new ROIs (12 mm radius) based on the results from our GLM analysis. These ROIs were defined in MNI  space (2 mm isotropic) and centred on manually selected voxels which showed peak values in the reversed slope of the contrast Familiar &gt; Unfamiliar. Overlap between ROIs was resolved manually.</div><ul><li>average number of voxels (and SD) per roi?</li></ul><div>ROI center coordinates in MNI space can be found under&nbsp;<i>roi_coords_38.csv</i> in our github repository (<a href="https://github.com/oliver-contier/famface-temporal-dynamics/">https://github.com/oliver-contier/famface-temporal-dynamics/</a>).</div><div>The ROI mask was projected from MNI space to the individual subject space using the inverse transformation matrices obtained during image preprocessing for our GLM using FSL's Flirt&nbsp;<cite class="ltx_cite raw v1">\citep{Jenkinson_2001,Jenkinson_2002}</cite> and ANTs&nbsp;<cite class="ltx_cite raw v1">\citep*{avants_advanced_2009}</cite>. Average parameter estimates within each ROI were extracted from the COPE and VARCOPE images produced by FSL from the first level analysis for the contrast of Familiar &gt; Unfamiliar as well as the simple main effects of the Familiar and Unfamiliar condition.</div><ul><li>Did the same also for the 3 clusters of our thresholded slope (instead of rois) and a CSF mask.</li><li>Describe how CSF mask was derived</li></ul><h2 data-label="774611" class="ltx_title_subsection">Code and data availability</h2><div>Un-thresholded statistical maps are available on&nbsp;<a href="http://neurovault.org" target="_blank">neurovault.org</a>&nbsp;<cite class="ltx_cite raw v1">\citep{Gorgolewski_2015}</cite> under&nbsp;<a href="http://neurovault.org/collections/2843/">http://neurovault.org/collections/2843/</a>.&nbsp;Analysis scripts can be found at the following GitHub repository:&nbsp;<a href="https://github.com/oliver-contier/famface-temporal-dynamics">https://github.com/oliver-contier/famface-temporal-dynamics</a>. All original data is available at&nbsp;<a href="http://datasets.datalad.org/?dir=/labs/gobbini/famface/data" target="_blank">http://datasets.datalad.org/?dir=/labs/gobbini/famface/data</a>.</div><h1 data-label="253477" class="ltx_title_section">Results</h1><h2 data-label="575557" class="ltx_title_subsection">GLM results</h2><div>Figure&nbsp;<span class="au-ref raw v1">\ref{563705}</span> shows the results from the confirmatory GLM analysis  projected onto a MNI template surface (using AFNI and SUMA;&nbsp;<cite class="ltx_cite raw v1">\citealt{Cox_1996,Saad}</cite>).</div>